---
id: llms
title: Large Language Models (LLMs)
sidebar_position: 1
---

This is a very incomplete list of current and ongoing LLMs. For a larger selection of LLMs, visit [Hugging Face](https://huggingface.co/models) for a selection of over 400,000 large language models.

1. [**GPT-4 (OpenAI)**](https://openai.com/research/gpt-4)
    - Description: The successor of GPT-3, a multimodal model that accepts image and text inputs, emitting text outputs.

2. [**BERT (Google)**](https://github.com/google-research/bert)
   - Description: A groundbreaking model for natural language processing tasks, especially effective in understanding the context of words in search queries.

3. [**T5 (Google)**](https://github.com/google-research/text-to-text-transfer-transformer)
   - Description: The “Text-to-Text Transfer Transformer” is designed to convert all NLP tasks into a text-to-text format, offering great versatility.

4. [**XLNet (Google/CMU)**](https://github.com/zihangdai/xlnet)
   - Description: An extension of the Transformer model, it outperforms BERT on several benchmarks by learning the bidirectional context of a word.

5. [**RoBERTa (Facebook AI)**](https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/)
   - Description: An optimized version of BERT, it has been fine-tuned for more robust performance on NLP tasks.

6. [**ELECTRA (Google)**](https://github.com/google-research/electra)
   - Description: A model designed to be more efficient than BERT for pre-training language representations.

7. [**Transformer (Google Brain)**](https://www.tensorflow.org/tutorials/text/transformer)
   - Description: The foundational architecture behind many subsequent models, introducing the innovative transformer mechanism.

8. [**ERNIE (Baidu)**](https://github.com/PaddlePaddle/ERNIE)
   - Description: An enhanced representation through knowledge integration model, which incorporates knowledge graphs for better language understanding.

9. [**DeBERTa (Microsoft)**](https://github.com/microsoft/DeBERTa)
    - Description: Enhances the BERT and RoBERTa models using disentangled attention and a new positional encoding technique.

10. [**Llama 2 (Meta)**](https://huggingface.co/meta-llama)
    - Description: A suite of models for general, chat, and code ranging in from 7 billion to 70 billion parameters.

### What is Hugging Face

[**Hugging Face**](https://huggingface.co/) is a technology company that specializes in artificial intelligence (AI), particularly in the field of natural language processing (NLP), which is the ability of computers to understand, interpret, and respond to human language. Their most notable contribution is the development of powerful AI models that can understand text and even write it in a way that seems very human-like. These models are used in various applications like chatbots, language translation, and content creation.

What makes Hugging Face stand out is its commitment to making AI accessible and easy to use. They offer a platform where developers, even those without deep technical knowledge, can use or improve these AI models. Additionally, they foster a collaborative community where people can share, learn, and build AI projects together. Their approach is very user-friendly, focusing on making AI technology more open and available to a wider range of people and industries.

### Further Resources

- [**The Busy Person’s Intro to Large Language Models by Andrej Karpathy (video)**](https://youtu.be/zjkBMFhNj_g?si=uxSUVs9T45z5j6_S)
- [**Busy Person's Intro to LLLMs Reading List**](https://blog.oxen.ai/reading-list-for-andrej-karpathys-intro-to-large-language-models-video/)

